{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AK-Tag\n",
    "Code for the retrieval of the \"Stellungnahmen\" (=Feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is following the documentation provided by the framework \"LangChain\" (https://python.langchain.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai langchain-chroma bs4 pypdf progressbar2 unstructured\n",
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai_api_key = os.getenv('openai_api_key')\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import progressbar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdfs_to_pages(folder_path):\n",
    "    \"\"\"\n",
    "    Convert PDF files in a specified folder to text.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The folder path where the PDF files are located.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of pages for each PDF file.\n",
    "    \"\"\"\n",
    "    # Get the list of PDF files in the folder\n",
    "    pdf_files = [file for file in os.listdir(folder_path) if file.endswith(\".pdf\")]\n",
    "\n",
    "    pdf_list = []\n",
    "\n",
    "    # Iterate over each PDF file and convert it to pages\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(folder_path, pdf_file)\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages = loader.load()\n",
    "        pdf_list.append(pages)\n",
    "        #print(f\"Converted {pdf_file} to {len(pages)} pages.\")\n",
    "\n",
    "    return pdf_list\n",
    "pdf_list  = convert_pdfs_to_pages(\"downloaded_pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pdf_text(pdf_list):\n",
    "    \"\"\"\n",
    "    Save the text of each PDF (multiple pages per PDF) in a separate file.\n",
    "\n",
    "    Args:\n",
    "        pdf_list (list): A list of PDF objects.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create the folder if it doesn't exist\n",
    "    folder_name = \"text_per_pdf\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    # Save the text of each PDF in a separate file\n",
    "    for i, pdf in enumerate(pdf_list):\n",
    "        pdf_name = pdf[0].metadata['source']\n",
    "        # Extracting the second half of the text\n",
    "        second_half = pdf_name.split(\"/\")[1]\n",
    "        # Replacing spaces with underscores\n",
    "        pdf_name_shortened = second_half.replace(' ', '_')\n",
    "\n",
    "        feedback_text = []\n",
    "        for j, page in enumerate(pdf):\n",
    "            feedback_text.append(page.page_content)\n",
    "            #print(page.page_content)   \n",
    "        with open(f\"{folder_name}/{pdf_name_shortened}.txt\", \"w\") as f: \n",
    "            f.write(\"\\n\".join(feedback_text))\n",
    "save_pdf_text(pdf_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key=openai_api_key,model=\"gpt-4-turbo-2024-04-09\")\n",
    "\n",
    "def summarize_with_gpt(text):\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following questions in German based only on the provided context:\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    Questions: {input}\"\"\")\n",
    "\n",
    "    document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    response = document_chain.invoke({\n",
    "        \"input\": \"Identify the key points raised by the stakeholder in their accompanying messages (and, if feasible, their attached documents) \\\n",
    "        Summarise the stakeholder feedback in bullets, grouping similar statements and highlighting divergent opinions \\\n",
    "        Cluster opinions according to positive and negative sentiment (supportive or against the proposed regulation) \\\n",
    "        Identify evidence from the inputs that can reinforce or contradict the proposed rules\",\n",
    "        \"context\": text\n",
    "    })\n",
    "    return(response)\n",
    "\n",
    "\n",
    "def summarize_each_feedback(folder_path):\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    folder_name = \"summarization\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    text_files = [file for file in os.listdir(folder_path) if file.endswith(\".txt\")]\n",
    "    print(text_files)\n",
    "    for text_file in text_files:\n",
    "        \n",
    "        # Check if the summary file already exists\n",
    "        summary_path = os.path.join(folder_name, text_file)\n",
    "        if os.path.exists(summary_path):\n",
    "            print(f\"Skipping existing summary for {text_file}\")\n",
    "            \n",
    "        text_path = os.path.join(folder_path, text_file)\n",
    "        loader = TextLoader(text_path)\n",
    "        text =  loader.load()\n",
    "        summarized_text = summarize_with_gpt(text)\n",
    "        file_name_without_extension = text_file.rsplit('.', 2)[0].rsplit('_', 1)[0]  # Remove the extension\n",
    "\n",
    "        with open(f\"{folder_name}/{text_file}\", \"w\") as f: \n",
    "            f.write(\"Feedback from: \"+file_name_without_extension + \"\\n\" + \"\\n\" + summarized_text)\n",
    "          \n",
    "summarize_each_feedback(\"text_per_pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# Reduce\n",
    "reduce_template = \"\"\"The following is set of summaries:\n",
    "{docs}\n",
    "Take these and distill it into a final, consolidated summary.\n",
    "Identify the key points raised by the stakeholders in their accompanying messages (and, if feasible, their attached documents)\n",
    "Summarise the stakeholder feedback in bullets, grouping similar statements and highlighting divergent opinions\n",
    "Cluster opinions according to positive and negative sentiment (supportive or against the proposed regulation)\n",
    "Identify evidence from the inputs that can reinforce or contradict the proposed rules\n",
    "Each stakeholder feedback starts with the line \\\"Feedback from: \\\". Underline the key aspects and provide examples from the provided summaries. Also, include the name of the stakeholder. List the names of very positive and very negative stakeholders.\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
    ")\n",
    "\n",
    "# Combines and iteratively reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=128000,\n",
    ")\n",
    "loader = DirectoryLoader('./summarization/', glob=\"*.txt\")\n",
    "docs = loader.load()\n",
    "meta_summarization = reduce_documents_chain.run(docs)\n",
    "\n",
    "file_name = \"./meta-summarization.txt\"\n",
    "with open(file_name, 'w') as file:\n",
    "    file.write(meta_summarization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option Batch upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorize_system_prompt = '''\n",
    "Identify the key points raised by the stakeholders in their accompanying messages (and, if feasible, their attached documents)\n",
    "Summarise the stakeholder feedback in bullets, grouping similar statements and highlighting divergent opinions\n",
    "Cluster opinions according to positive and negative sentiment (supportive or against the proposed regulation)\n",
    "Identify evidence from the inputs that can reinforce or contradict the proposed rules\n",
    "\n",
    "Each stakeholder feedback starts with the line \"Feedback from: \".\n",
    "'''\n",
    "\n",
    "task = {\n",
    "        \"custom_id\": f\"task-generate-summary\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4-turbo-2024-04-09\",\n",
    "            \"temperature\": 0.1,\n",
    "            \"response_format\": { \n",
    "                \"type\": \"json_object\"\n",
    "            },\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": categorize_system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": all_text\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "\n",
    "import json\n",
    "file_name = \"./summarization-batch-job.jsonl\"\n",
    "with open(file_name, 'w') as file:\n",
    "    file.write(json.dumps(task) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
